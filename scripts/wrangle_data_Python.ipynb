{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages\n",
    "\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "import shapely.wkt\n",
    "\n",
    "# Need to enable this to allow work with larger datasets (https://altair-viz.github.io/user_guide/faq.html)\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "# source: https://automating-gis-processes.github.io/2017/lessons/L3/point-in-polygon.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.cityofnewyork.us/api/views/vfnx-vebw/rows.csv'\n",
    "\n",
    "squirrel_data = pd.read_csv(url, usecols = ['X', 'Y', 'Unique Squirrel ID', 'Hectare', 'Shift', 'Date',\n",
    "       'Hectare Squirrel Number', 'Age', 'Primary Fur Color', 'Location', 'Kuks', 'Quaas', 'Moans', 'Running', 'Chasing', 'Climbing', 'Eating',\n",
    "       'Foraging', 'Approaches', 'Indifferent', 'Runs from', 'Lat/Long'])\n",
    "# source (data): https://catalog.data.gov/dataset/2018-central-park-squirrel-census-hectare-data\n",
    "\n",
    "# Replace NaN with \"Unknown\"\n",
    "squirrel_data = squirrel_data.fillna(value = \"Unknown\")\n",
    "# Convert lat/long column of squirrel data from string to point\n",
    "squirrel_data[\"Lat/Long\"] = squirrel_data[\"Lat/Long\"].apply(shapely.wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data needed to map data on park map\n",
    "geojson_filepath = '../data/central_park_geo.geojson'\n",
    "\n",
    "def open_geojson(path):\n",
    "    \"\"\"\n",
    "    Opens a geojson file at \"path\" filepath\n",
    "    \"\"\"\n",
    "    with open(path) as json_data:\n",
    "        d = json.load(json_data)\n",
    "    return d\n",
    "\n",
    "def get_geopandas_df(path):\n",
    "    \"\"\"\n",
    "    Creates geopandas dataframe from geeojson file \n",
    "    at \"path\" filepath\n",
    "    \"\"\"\n",
    "    open_json = open_geojson(path)\n",
    "    gdf = gpd.GeoDataFrame.from_features((open_json))\n",
    "    return gdf\n",
    "\n",
    "# Create geopandas dataframe from Central Park geoJson file\n",
    "gdf = get_geopandas_df(geojson_filepath)\n",
    "\n",
    "gdf.at[list(gdf.query('location == \"CPW, W 97 St, West Drive, W 100 St\"').index), 'sitename'] = \"Central Park West (Zone 1)\"\n",
    "gdf.at[list(gdf.query('location == \"CPW, 85 St Transverse, West Drive To 96 St\"').index), 'sitename'] = \"Central Park West (Zone 2)\"\n",
    "gdf.at[list(gdf.query('location == \"West Drive, CPW, 65 St Transverse\"').index), 'sitename'] = \"Central Park West (Zone 3)\"\n",
    "gdf.at[list(gdf.query('location == \"66 St To 72 St, CPW To West Drive\"').index), 'sitename'] = \"Central Park West (Zone 4)\"\n",
    "\n",
    "# source (code): https://medium.com/dataexplorations/creating-choropleth-maps-in-altair-eeb7085779a1\n",
    "# source (map data): https://data.cityofnewyork.us/City-Government/Parks-Zones/rjaj-zgq7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'sitename' from mapping data to location of each squirrel observation\n",
    "# in 'squirrel_data'\n",
    "squirrel_data[\"sitename\"] = \"not set\"\n",
    "\n",
    "def map_park_site(point):\n",
    "    \"\"\"\n",
    "    Matches point location of observation in squirrel_data to polygon\n",
    "    in gdf that it lies within. Returns \"sitename\" of polygon.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    point\n",
    "        shapely.point object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        sitename value of polygon that point lies within\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    map_park_site(Point((73, 43)))\n",
    "    > \"Great Lawn\"\n",
    "    -------------\n",
    "    \"\"\"\n",
    "    for poly in gdf[\"geometry\"]:\n",
    "        if point.within(poly):\n",
    "            i = list(gdf['sitename'].loc[gdf['geometry'] == poly])\n",
    "            val = i[0]\n",
    "            return val\n",
    "\n",
    "# Map sitename to polygons\n",
    "squirrel_data['sitename'] = squirrel_data['Lat/Long'].apply(map_park_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrel_data = pd.merge(gdf, squirrel_data, on = 'sitename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrel_data.columns = [column.replace(' ', '_') for column in list(squirrel_data.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare squirrel data to graph squirrel counts by park area\n",
    "squirrel_total_count = squirrel_data[['sitename','Unique_Squirrel_ID',\n",
    "                                      'Running', 'Chasing', 'Climbing', \n",
    "                                      'Eating', 'Foraging', 'Kuks', 'Quaas',\n",
    "                                      'Moans', 'Approaches']].groupby('sitename').agg({'Unique_Squirrel_ID':'count',\n",
    "                                                                                       'Running':'sum', \n",
    "                                                                                       'Chasing':'sum', \n",
    "                                                                                       'Climbing':'sum',\n",
    "                                                                                       'Eating':'sum', \n",
    "                                                                                       'Foraging':'sum', \n",
    "                                                                                       'Kuks':'sum', \n",
    "                                                                                       'Quaas':'sum',\n",
    "                                                                                       'Moans':'sum', \n",
    "                                                                                       'Approaches':'sum'}).reset_index()\n",
    "\n",
    "# source (code): https://medium.com/dataexplorations/creating-choropleth-maps-in-altair-eeb7085779a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrel_total_count['Vocalizations'] = squirrel_total_count['Kuks'] + squirrel_total_count['Quaas'] + squirrel_total_count['Moans'] \n",
    "#squirrel_total_count.drop(columns = ['Kuks', 'Quaas', 'Moans'])\n",
    "\n",
    "squirrel_total_count['Running_or_chasing'] = squirrel_total_count['Running'] + squirrel_total_count['Chasing']\n",
    "#squirrel_total_count.drop(columns = ['Running', 'Chasing'])\n",
    "\n",
    "squirrel_total_count['Eating_or_foraging'] = squirrel_total_count['Eating'] + squirrel_total_count['Foraging']\n",
    "squirrel_total_count = squirrel_total_count.drop(columns = ['Eating', 'Foraging', 'Running', 'Chasing', 'Kuks', 'Quaas', 'Moans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrel_diff_count = squirrel_data[['sitename',\n",
    "                                      'Shift',\n",
    "                                      'Unique_Squirrel_ID',]].groupby(['sitename',\n",
    "                                                                       'Shift']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrel_diff_df = squirrel_diff_count.pivot(index = 'sitename', columns = 'Shift', values = 'Unique_Squirrel_ID').reset_index()\n",
    "squirrel_diff_df['Count_diff (AM - PM)'] = squirrel_diff_df['AM'] - squirrel_diff_df['PM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrel_count = pd.merge(squirrel_total_count, squirrel_diff_df[['sitename','Count_diff (AM - PM)']], on = 'sitename', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "squirrel_count.to_csv('../data/squirrel_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
